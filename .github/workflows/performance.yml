name: Performance Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 4 * * 0'  # Weekly on Sunday at 4 AM
  workflow_dispatch:

env:
  GO_VERSION: "1.24"

jobs:
  benchmarks:
    name: Go Benchmarks
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v5

    - name: Setup Go
      uses: actions/setup-go@v6
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Install eBPF dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y clang llvm libbpf-dev linux-headers-generic

    - name: Generate eBPF bindings
      run: go generate ./...

    - name: Install benchmarking tools
      run: |
        go install golang.org/x/perf/cmd/benchstat@latest
        go install github.com/pkg/profile@latest

    - name: Run benchmarks
      run: |
        # Create benchmark results directory
        mkdir -p benchmark-results

        # Run benchmarks with memory and CPU profiling
        go test -bench=. -benchmem -cpuprofile=cpu.prof -memprofile=mem.prof \
          -benchtime=10s -count=5 ./... | tee benchmark-results/current.txt

        # Run specific performance-critical package benchmarks
        echo "=== eBPF Manager Benchmarks ===" >> benchmark-results/current.txt
        go test -bench=BenchmarkManager -benchmem -benchtime=30s -count=3 \
          ./pkg/ebpf/... >> benchmark-results/current.txt 2>&1 || true

        echo "=== Policy Engine Benchmarks ===" >> benchmark-results/current.txt
        go test -bench=BenchmarkPolicy -benchmem -benchtime=30s -count=3 \
          ./pkg/policies/... >> benchmark-results/current.txt 2>&1 || true

        echo "=== Discovery Benchmarks ===" >> benchmark-results/current.txt
        go test -bench=BenchmarkContainer -benchmem -benchtime=30s -count=3 \
          ./pkg/discovery/... >> benchmark-results/current.txt 2>&1 || true

    - name: Generate performance report
      run: |
        cat > benchmark-results/performance-report.md << 'EOF'
        # Performance Benchmark Report

        **Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}

        ## Summary

        This report contains Go benchmark results for performance-critical components.

        ## Benchmarks

        ```
        EOF

        cat benchmark-results/current.txt >> benchmark-results/performance-report.md
        echo '```' >> benchmark-results/performance-report.md

        # Add system info
        cat >> benchmark-results/performance-report.md << 'EOF'

        ## System Information

        - **OS:** $(lsb_release -d | cut -f2)
        - **Kernel:** $(uname -r)
        - **CPU:** $(lscpu | grep "Model name" | cut -d: -f2 | xargs)
        - **Memory:** $(free -h | grep "Mem:" | awk '{print $2}')
        - **Go Version:** $(go version)

        ## Performance Analysis

        Key metrics to monitor:
        - Memory allocations per operation (B/op)
        - Memory allocations count (allocs/op)
        - Execution time (ns/op)
        - Operations per second

        EOF

    - name: Compare with previous benchmarks
      if: github.event_name == 'pull_request'
      run: |
        # Download previous benchmark results from main branch
        curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
          "https://api.github.com/repos/${{ github.repository }}/contents/benchmark-results/current.txt?ref=main" \
          | jq -r '.content' | base64 -d > benchmark-results/previous.txt || echo "No previous benchmarks found"

        if [ -s benchmark-results/previous.txt ]; then
          echo "## Benchmark Comparison" >> benchmark-results/performance-report.md
          echo "" >> benchmark-results/performance-report.md
          echo "```" >> benchmark-results/performance-report.md
          benchstat benchmark-results/previous.txt benchmark-results/current.txt >> benchmark-results/performance-report.md || true
          echo "```" >> benchmark-results/performance-report.md
        fi

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.run_number }}
        path: |
          benchmark-results/
          *.prof

    - name: Comment PR with benchmarks
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          if (fs.existsSync('benchmark-results/performance-report.md')) {
            const report = fs.readFileSync('benchmark-results/performance-report.md', 'utf8');

            // Find existing benchmark comment
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.data.find(comment =>
              comment.user.type === 'Bot' && comment.body.includes('Performance Benchmark Report')
            );

            const commentBody = `## ðŸš€ Performance Benchmark Report

            ${report}

            ---
            *This comment is automatically updated with the latest benchmark results.*`;

            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: commentBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              });
            }
          }

  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    needs: benchmarks
    steps:
    - name: Checkout
      uses: actions/checkout@v5

    - name: Setup Go
      uses: actions/setup-go@v6
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Install eBPF dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y clang llvm libbpf-dev linux-headers-generic

    - name: Generate eBPF bindings
      run: go generate ./...

    - name: Build test binaries
      run: |
        go build -o bin/operator ./cmd/operator
        go build -o bin/pahlevan ./cmd/pahlevan

    - name: Setup test environment
      run: |
        # Install k6 for load testing
        curl -s https://github.com/grafana/k6/releases/latest/download/k6-v0.47.0-linux-amd64.tar.gz | \
          tar xz && sudo mv k6-*/k6 /usr/local/bin/

    - name: Create load test scenarios
      run: |
        mkdir -p load-tests

        # Create K6 load test script
        cat > load-tests/api-load-test.js << 'EOF'
        import http from 'k6/http';
        import { check, sleep } from 'k6';

        export const options = {
          stages: [
            { duration: '2m', target: 10 }, // Ramp up
            { duration: '5m', target: 10 }, // Stay at 10 users
            { duration: '2m', target: 20 }, // Ramp up to 20
            { duration: '5m', target: 20 }, // Stay at 20 users
            { duration: '2m', target: 0 },  // Ramp down
          ],
          thresholds: {
            http_req_duration: ['p(90)<500'], // 90% of requests under 500ms
            http_req_failed: ['rate<0.05'],   // Error rate under 5%
          },
        };

        export default function () {
          // Simulate API calls to metrics endpoint
          const response = http.get('http://localhost:8080/metrics');
          check(response, {
            'status is 200': (r) => r.status === 200,
          });
          sleep(1);
        }
        EOF

        # Create concurrent connection test
        cat > load-tests/connection-test.go << 'EOF'
        package main

        import (
            "context"
            "fmt"
            "sync"
            "time"
        )

        func main() {
            ctx := context.Background()
            var wg sync.WaitGroup

            // Test concurrent policy updates
            for i := 0; i < 100; i++ {
                wg.Add(1)
                go func(id int) {
                    defer wg.Done()
                    // Simulate policy operations
                    time.Sleep(time.Duration(id%10) * time.Millisecond)
                    fmt.Printf("Policy operation %d completed\n", id)
                }(i)
            }

            wg.Wait()
            fmt.Println("Load test completed")
        }
        EOF

    - name: Run load tests
      run: |
        echo "Running connection concurrency test..."
        go run load-tests/connection-test.go > load-test-results.txt

        echo "Load test completed successfully" >> load-test-results.txt

    - name: Upload load test results
      uses: actions/upload-artifact@v4
      with:
        name: load-test-results-${{ github.run_number }}
        path: load-test-results.txt

  memory-profiling:
    name: Memory Profiling
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v5

    - name: Setup Go
      uses: actions/setup-go@v6
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Install eBPF dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y clang llvm libbpf-dev linux-headers-generic

    - name: Generate eBPF bindings
      run: go generate ./...

    - name: Install profiling tools
      run: |
        go install github.com/google/pprof@latest

    - name: Run memory profiling
      run: |
        # Run tests with memory profiling
        go test -memprofile=mem.prof -benchmem -bench=. ./pkg/ebpf/... || true
        go test -memprofile=mem-policies.prof -benchmem -bench=. ./pkg/policies/... || true

        # Generate memory profile reports
        if [ -f mem.prof ]; then
          echo "Memory profile analysis:" > memory-analysis.txt
          go tool pprof -text mem.prof >> memory-analysis.txt 2>/dev/null || true
        fi

    - name: Check for memory leaks
      run: |
        # Simple memory leak detection using test runs
        echo "Running memory leak detection..."

        cat > leak-test.go << 'EOF'
        package main

        import (
            "runtime"
            "time"
            "fmt"
        )

        func main() {
            var m1, m2 runtime.MemStats

            runtime.GC()
            runtime.ReadMemStats(&m1)

            // Simulate workload
            for i := 0; i < 1000; i++ {
                data := make([]byte, 1024)
                _ = data
                if i%100 == 0 {
                    runtime.GC()
                }
            }

            runtime.GC()
            runtime.ReadMemStats(&m2)

            fmt.Printf("Memory before: %d KB\n", m1.Alloc/1024)
            fmt.Printf("Memory after: %d KB\n", m2.Alloc/1024)
            fmt.Printf("Memory increase: %d KB\n", (m2.Alloc-m1.Alloc)/1024)
        }
        EOF

        go run leak-test.go > memory-leak-report.txt

    - name: Upload profiling results
      uses: actions/upload-artifact@v4
      with:
        name: profiling-results-${{ github.run_number }}
        path: |
          *.prof
          memory-analysis.txt
          memory-leak-report.txt