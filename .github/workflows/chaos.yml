name: Chaos Engineering & Resilience

on:
  schedule:
    - cron: '0 3 * * 1'  # Weekly on Monday at 3 AM
  workflow_dispatch:
    inputs:
      chaos_intensity:
        description: 'Chaos intensity level (low/medium/high)'
        required: true
        default: 'medium'
        type: choice
        options:
          - low
          - medium
          - high
      target_namespace:
        description: 'Target namespace for chaos testing'
        required: false
        default: 'pahlevan-chaos-test'

env:
  GO_VERSION: "1.24"

jobs:
  chaos-testing:
    name: Chaos Engineering Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      matrix:
        scenario: [
          "pod-failure",
          "network-partition",
          "resource-exhaustion",
          "disk-pressure",
          "node-failure",
          "operator-restart"
        ]
      fail-fast: false
    steps:
    - name: Checkout
      uses: actions/checkout@v5

    - name: Setup Go
      uses: actions/setup-go@v6
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y clang llvm libbpf-dev linux-headers-generic

    - name: Generate eBPF bindings
      run: go generate ./...

    - name: Setup Helm
      uses: azure/setup-helm@v4
      with:
        version: 'v3.14.0'

    - name: Setup Kubernetes cluster
      uses: helm/kind-action@v1
      with:
        cluster_name: chaos-test-cluster
        kubectl_version: v1.29.0
        node_image: kindest/node:v1.29.0
        config: |
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
          - role: control-plane
          - role: worker
          - role: worker

    - name: Install Chaos Mesh
      run: |
        # Install Chaos Mesh for chaos engineering
        curl -sSL https://mirrors.chaos-mesh.org/install.sh | bash -s -- --local kind --name chaos-test-cluster

        # Wait for Chaos Mesh to be ready
        kubectl wait --for=condition=Ready pods -l app.kubernetes.io/component=controller-manager -n chaos-mesh --timeout=300s

    - name: Build and load Pahlevan image
      run: |
        docker build -t pahlevan:chaos-test .
        kind load docker-image pahlevan:chaos-test --name chaos-test-cluster

    - name: Deploy Pahlevan for chaos testing
      run: |
        # Create test namespace
        kubectl create namespace ${{ inputs.target_namespace || 'pahlevan-chaos-test' }}

        # Deploy Pahlevan
        helm install pahlevan-chaos ./charts/pahlevan-operator \
          --namespace ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} \
          --set image.repository=pahlevan \
          --set image.tag=chaos-test \
          --set image.pullPolicy=Never \
          --set replicas=2 \
          --wait --timeout=5m

    - name: Deploy test workloads
      run: |
        # Deploy various test workloads to monitor during chaos
        cat << 'EOF' | kubectl apply -f -
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: test-workload-${{ matrix.scenario }}
          namespace: ${{ inputs.target_namespace || 'pahlevan-chaos-test' }}
          labels:
            app: test-workload
            chaos-scenario: ${{ matrix.scenario }}
        spec:
          replicas: 3
          selector:
            matchLabels:
              app: test-workload
              chaos-scenario: ${{ matrix.scenario }}
          template:
            metadata:
              labels:
                app: test-workload
                chaos-scenario: ${{ matrix.scenario }}
                security.pahlevan.io/monitor: "true"
            spec:
              containers:
              - name: test-app
                image: busybox:1.35
                command: ["sh", "-c"]
                args:
                - |
                  while true; do
                    echo "$(date): Test workload running - scenario: ${{ matrix.scenario }}"
                    # Generate some file system activity
                    echo "test data" > /tmp/test-$RANDOM.txt
                    ls -la /tmp/ > /dev/null
                    sleep 5
                  done
                resources:
                  requests:
                    memory: "32Mi"
                    cpu: "10m"
                  limits:
                    memory: "64Mi"
                    cpu: "50m"
        EOF

        kubectl wait --for=condition=available deployment/test-workload-${{ matrix.scenario }} \
          -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} --timeout=120s

    - name: Run chaos experiment - ${{ matrix.scenario }}
      run: |
        chaos_intensity="${{ inputs.chaos_intensity || 'medium' }}"
        namespace="${{ inputs.target_namespace || 'pahlevan-chaos-test' }}"

        echo "Running chaos experiment: ${{ matrix.scenario }} with intensity: $chaos_intensity"

        case "${{ matrix.scenario }}" in
          "pod-failure")
            cat << EOF | kubectl apply -f -
        apiVersion: chaos-mesh.org/v1alpha1
        kind: PodChaos
        metadata:
          name: pod-failure-test
          namespace: $namespace
        spec:
          action: pod-failure
          mode: fixed-percent
          value: "33"
          duration: "60s"
          selector:
            namespaces:
              - $namespace
            labelSelectors:
              app: test-workload
        EOF
            ;;

          "network-partition")
            cat << EOF | kubectl apply -f -
        apiVersion: chaos-mesh.org/v1alpha1
        kind: NetworkChaos
        metadata:
          name: network-partition-test
          namespace: $namespace
        spec:
          action: partition
          mode: fixed-percent
          value: "50"
          duration: "60s"
          selector:
            namespaces:
              - $namespace
            labelSelectors:
              app: test-workload
          direction: both
        EOF
            ;;

          "resource-exhaustion")
            cat << EOF | kubectl apply -f -
        apiVersion: chaos-mesh.org/v1alpha1
        kind: StressChaos
        metadata:
          name: memory-stress-test
          namespace: $namespace
        spec:
          mode: fixed-percent
          value: "50"
          duration: "60s"
          selector:
            namespaces:
              - $namespace
            labelSelectors:
              app: test-workload
          stressors:
            memory:
              workers: 1
              size: "32MB"
        EOF
            ;;

          "disk-pressure")
            cat << EOF | kubectl apply -f -
        apiVersion: chaos-mesh.org/v1alpha1
        kind: IOChaos
        metadata:
          name: disk-pressure-test
          namespace: $namespace
        spec:
          action: latency
          mode: fixed-percent
          value: "50"
          duration: "60s"
          selector:
            namespaces:
              - $namespace
            labelSelectors:
              app: test-workload
          delay: "100ms"
          path: "/tmp"
        EOF
            ;;

          "operator-restart")
            # Restart Pahlevan operator pods
            kubectl delete pods -l app.kubernetes.io/name=pahlevan -n $namespace
            sleep 10
            kubectl wait --for=condition=Ready pods -l app.kubernetes.io/name=pahlevan -n $namespace --timeout=120s
            ;;

          *)
            echo "Unknown chaos scenario: ${{ matrix.scenario }}"
            exit 1
            ;;
        esac

    - name: Monitor system during chaos
      run: |
        echo "Monitoring system behavior during chaos experiment..."

        # Monitor for 2 minutes
        for i in {1..24}; do
          echo "=== Monitoring iteration $i/24 ==="

          # Check pod status
          echo "Pod status:"
          kubectl get pods -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} || true

          # Check operator logs for errors
          echo "Checking operator logs for errors:"
          kubectl logs -l app.kubernetes.io/name=pahlevan -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} \
            --tail=20 --since=30s | grep -i -E "(error|panic|fatal)" || echo "No critical errors found"

          # Check test workload status
          kubectl get deployment test-workload-${{ matrix.scenario }} \
            -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} \
            -o jsonpath='{.status.readyReplicas}/{.spec.replicas}' || echo "0/0"
          echo " ready replicas for test workload"

          sleep 5
        done

    - name: Validate system recovery
      run: |
        echo "Validating system recovery after chaos experiment..."

        # Clean up chaos experiments
        kubectl delete podchaos,networkchaos,stresschaos,iochaos --all \
          -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} || true

        # Wait for system to stabilize
        sleep 30

        # Verify Pahlevan operator is healthy
        kubectl wait --for=condition=available deployment/pahlevan-operator \
          -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} --timeout=120s

        # Verify test workloads recovered
        kubectl wait --for=condition=available deployment/test-workload-${{ matrix.scenario }} \
          -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} --timeout=120s

        # Check for no crash loops
        restart_count=$(kubectl get pods -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} \
          -o jsonpath='{.items[*].status.containerStatuses[*].restartCount}' | tr ' ' '\n' | \
          awk '{sum += $1} END {print sum}')

        echo "Total restart count: $restart_count"
        if [ "$restart_count" -gt 10 ]; then
          echo "WARNING: High restart count detected: $restart_count"
          kubectl describe pods -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }}
        fi

    - name: Generate chaos test report
      if: always()
      run: |
        mkdir -p chaos-reports

        cat > chaos-reports/chaos-report-${{ matrix.scenario }}.md << EOF
        # Chaos Engineering Report - ${{ matrix.scenario }}

        **Date:** $(date -u)
        **Scenario:** ${{ matrix.scenario }}
        **Intensity:** ${{ inputs.chaos_intensity || 'medium' }}
        **Namespace:** ${{ inputs.target_namespace || 'pahlevan-chaos-test' }}

        ## System State During Chaos

        \`\`\`
        $(kubectl get pods -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} -o wide || echo "Unable to get pod status")
        \`\`\`

        ## Operator Logs (Last 50 lines)

        \`\`\`
        $(kubectl logs -l app.kubernetes.io/name=pahlevan -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} --tail=50 || echo "Unable to get logs")
        \`\`\`

        ## Events During Test

        \`\`\`
        $(kubectl get events -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} --sort-by='.lastTimestamp' || echo "Unable to get events")
        \`\`\`

        ## Recovery Status

        - Operator Recovery: $(kubectl get deployment pahlevan-operator -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} -o jsonpath='{.status.conditions[?(@.type=="Available")].status}' || echo "Unknown")
        - Workload Recovery: $(kubectl get deployment test-workload-${{ matrix.scenario }} -n ${{ inputs.target_namespace || 'pahlevan-chaos-test' }} -o jsonpath='{.status.conditions[?(@.type=="Available")].status}' || echo "Unknown")

        EOF

    - name: Upload chaos test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: chaos-test-results-${{ matrix.scenario }}-${{ github.run_number }}
        path: chaos-reports/

  resilience-summary:
    name: Resilience Test Summary
    runs-on: ubuntu-latest
    needs: chaos-testing
    if: always()
    steps:
    - name: Download all chaos test results
      uses: actions/download-artifact@v4
      with:
        path: all-chaos-results
        pattern: chaos-test-results-*

    - name: Generate comprehensive resilience report
      run: |
        echo "# Comprehensive Resilience Test Report" > resilience-summary.md
        echo "" >> resilience-summary.md
        echo "**Date:** $(date -u)" >> resilience-summary.md
        echo "**Commit:** ${{ github.sha }}" >> resilience-summary.md
        echo "" >> resilience-summary.md

        echo "## Test Results Summary" >> resilience-summary.md
        echo "" >> resilience-summary.md

        # Process each scenario result
        for scenario in pod-failure network-partition resource-exhaustion disk-pressure node-failure operator-restart; do
          echo "### $scenario" >> resilience-summary.md
          if ls all-chaos-results/chaos-test-results-$scenario-*/chaos-report-$scenario.md 1> /dev/null 2>&1; then
            echo "✅ Completed" >> resilience-summary.md
          else
            echo "❌ Failed or Incomplete" >> resilience-summary.md
          fi
          echo "" >> resilience-summary.md
        done

        echo "## Recommendations" >> resilience-summary.md
        echo "" >> resilience-summary.md
        echo "- Monitor pod restart counts regularly" >> resilience-summary.md
        echo "- Implement health checks for faster recovery detection" >> resilience-summary.md
        echo "- Consider implementing circuit breakers for external dependencies" >> resilience-summary.md
        echo "- Regular chaos engineering exercises recommended" >> resilience-summary.md

    - name: Upload comprehensive report
      uses: actions/upload-artifact@v4
      with:
        name: resilience-test-summary-${{ github.run_number }}
        path: resilience-summary.md